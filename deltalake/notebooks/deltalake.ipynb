{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99841464-c7bc-4760-ab49-ed7712ad38db",
   "metadata": {},
   "source": [
    "Realizando importações para o funcionamento da aplicação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c30581a-1812-4396-a87c-269e7a326447",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import os\n",
    "import pyspark\n",
    "from delta import *\n",
    "from delta.tables import *\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2cdc3f",
   "metadata": {},
   "source": [
    "Criando uma sessão do Spark com Delta Lake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8befd5ed-1229-45f3-b0d0-894947e2f19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = pyspark.sql.SparkSession.builder.appName(\"DeltaLake\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .config(\"spark.jars.packages\", 'org.apache.hadoop:hadoop-aws:3.3.4') \\\n",
    "    .config('spark.hadoop.fs.s3a.endpoint', \"http://minio:9000\") \\\n",
    "    .config('spark.hadoop.fs.s3a.access.key', \"admin\") \\\n",
    "    .config('spark.hadoop.fs.s3a.secret.key', \"password\") \\\n",
    "    .config('spark.hadoop.fs.s3a.path.style.access', \"true\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f82de466-f804-4346-af46-9b58beea3c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      "io.delta#delta-spark_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-eae98d78-c799-4e9c-a130-af2e21a09d27;1.0\n",
      "\tconfs: [default]\n",
      "\tfound io.delta#delta-spark_2.12;3.1.0 in central\n",
      "\tfound io.delta#delta-storage;3.1.0 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.9.3 in central\n",
      "downloading https://repo1.maven.org/maven2/io/delta/delta-spark_2.12/3.1.0/delta-spark_2.12-3.1.0.jar ...\n",
      "\t[SUCCESSFUL ] io.delta#delta-spark_2.12;3.1.0!delta-spark_2.12.jar (6679ms)\n",
      "downloading https://repo1.maven.org/maven2/io/delta/delta-storage/3.1.0/delta-storage-3.1.0.jar ...\n",
      "\t[SUCCESSFUL ] io.delta#delta-storage;3.1.0!delta-storage.jar (364ms)\n",
      "downloading https://repo1.maven.org/maven2/org/antlr/antlr4-runtime/4.9.3/antlr4-runtime-4.9.3.jar ...\n",
      "\t[SUCCESSFUL ] org.antlr#antlr4-runtime;4.9.3!antlr4-runtime.jar (449ms)\n",
      ":: resolution report :: resolve 5977ms :: artifacts dl 7507ms\n",
      "\t:: modules in use:\n",
      "\tio.delta#delta-spark_2.12;3.1.0 from central in [default]\n",
      "\tio.delta#delta-storage;3.1.0 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.9.3 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   3   |   3   |   3   |   0   ||   3   |   3   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-eae98d78-c799-4e9c-a130-af2e21a09d27\n",
      "\tconfs: [default]\n",
      "\t3 artifacts copied, 0 already retrieved (5727kB/46ms)\n",
      "24/04/25 20:13:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60dfca8c",
   "metadata": {},
   "source": [
    "Importando base de dados e criando tabela no formato Delta no Min.IO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea4ab8fe-ad14-424c-8466-4ce664f149e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando criação da tabela...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 20:13:31 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n",
      "24/04/25 20:13:40 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "24/04/25 20:14:01 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(\"Iniciando criação da tabela...\")\n",
    "\n",
    "root = os.path.dirname(os.getcwd())\n",
    "\n",
    "climate_change_df = spark.read.parquet(\"{0}/data/climate_change.parquet\".format(root))\n",
    "climate_change_df.write.save(mode=\"overwrite\", path=\"s3a://warehouse/deltalake_tables\", format=\"delta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6ad22d",
   "metadata": {},
   "source": [
    "Checando os dados da tabela recém criada dentro do Min.IO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf1a9b4d-163b-4594-9e93-ad46c53a10d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+-----------------------------+------------+-------+--------+---------+\n",
      "|        dt|AverageTemperature|AverageTemperatureUncertainty|        City|Country|Latitude|Longitude|\n",
      "+----------+------------------+-----------------------------+------------+-------+--------+---------+\n",
      "|1832-01-01|            23.173|                        1.692|Porto Alegre| Brazil|  29.74S|   51.69W|\n",
      "|1832-02-01|             22.93|                        2.661|Porto Alegre| Brazil|  29.74S|   51.69W|\n",
      "|1832-03-01|            21.281|                        1.826|Porto Alegre| Brazil|  29.74S|   51.69W|\n",
      "|1832-04-01|            17.697|                        2.482|Porto Alegre| Brazil|  29.74S|   51.69W|\n",
      "|1832-05-01|            14.214|                        2.263|Porto Alegre| Brazil|  29.74S|   51.69W|\n",
      "+----------+------------------+-----------------------------+------------+-------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cc_df = spark.read.load(\"s3a://warehouse/deltalake_tables\", format=\"delta\")\n",
    "\n",
    "cc_df.filter((cc_df[\"City\"] == \"Porto Alegre\") & (cc_df[\"Country\"] == \"Brazil\")).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6f4bd3",
   "metadata": {},
   "source": [
    "Atualizando dados na tabela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92854ae0-16a4-4422-8d68-745fa3702505",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+-----------------------------+------------+--------------+--------+---------+\n",
      "|        dt|AverageTemperature|AverageTemperatureUncertainty|        City|       Country|Latitude|Longitude|\n",
      "+----------+------------------+-----------------------------+------------+--------------+--------+---------+\n",
      "|1832-01-01|            23.173|                        1.692|Porto Alegre|Exemplo Update|  29.74S|   51.69W|\n",
      "|1832-02-01|             22.93|                        2.661|Porto Alegre|Exemplo Update|  29.74S|   51.69W|\n",
      "|1832-03-01|            21.281|                        1.826|Porto Alegre|Exemplo Update|  29.74S|   51.69W|\n",
      "|1832-04-01|            17.697|                        2.482|Porto Alegre|Exemplo Update|  29.74S|   51.69W|\n",
      "|1832-05-01|            14.214|                        2.263|Porto Alegre|Exemplo Update|  29.74S|   51.69W|\n",
      "+----------+------------------+-----------------------------+------------+--------------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cc_table = DeltaTable.forPath(spark, \"s3a://warehouse/deltalake_tables\")\n",
    "\n",
    "cc_table.update(\n",
    "    condition=expr(\"City == 'Porto Alegre'\"),\n",
    "    set={\"Country\": lit(\"Exemplo Update\")})\n",
    "\n",
    "cc_df = cc_table.toDF()\n",
    "cc_df.filter(cc_df[\"City\"] == \"Porto Alegre\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9415a9",
   "metadata": {},
   "source": [
    "Deletando dados da tabela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad7be421",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+-----------------------------+----+-------+--------+---------+\n",
      "| dt|AverageTemperature|AverageTemperatureUncertainty|City|Country|Latitude|Longitude|\n",
      "+---+------------------+-----------------------------+----+-------+--------+---------+\n",
      "+---+------------------+-----------------------------+----+-------+--------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cc_table = DeltaTable.forPath(spark, \"s3a://warehouse/deltalake_tables\")\n",
    "\n",
    "cc_table.delete(expr(\"City == 'Porto Alegre'\"))\n",
    "\n",
    "cc_df = cc_table.toDF()\n",
    "cc_df.filter(cc_df[\"City\"] == \"Porto Alegre\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e016158",
   "metadata": {},
   "source": [
    "Demonstração da funcionalidade de histórico do Delta Lake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f5f106",
   "metadata": {},
   "source": [
    "Tabela anterior a atualização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37a4c9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+-----------------------------+------------+-------+--------+---------+\n",
      "|        dt|AverageTemperature|AverageTemperatureUncertainty|        City|Country|Latitude|Longitude|\n",
      "+----------+------------------+-----------------------------+------------+-------+--------+---------+\n",
      "|1832-01-01|            23.173|                        1.692|Porto Alegre| Brazil|  29.74S|   51.69W|\n",
      "|1832-02-01|             22.93|                        2.661|Porto Alegre| Brazil|  29.74S|   51.69W|\n",
      "|1832-03-01|            21.281|                        1.826|Porto Alegre| Brazil|  29.74S|   51.69W|\n",
      "|1832-04-01|            17.697|                        2.482|Porto Alegre| Brazil|  29.74S|   51.69W|\n",
      "|1832-05-01|            14.214|                        2.263|Porto Alegre| Brazil|  29.74S|   51.69W|\n",
      "+----------+------------------+-----------------------------+------------+-------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_zero = spark.read.format(\"delta\").option(\"versionAsOf\", 0).load(\"s3a://warehouse/deltalake_tables\")\n",
    "df_zero.filter(df_zero[\"City\"] == \"Porto Alegre\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc82747e",
   "metadata": {},
   "source": [
    "Tabela após a atualização e anterior ao delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1633bf46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+-----------------------------+------------+--------------+--------+---------+\n",
      "|        dt|AverageTemperature|AverageTemperatureUncertainty|        City|       Country|Latitude|Longitude|\n",
      "+----------+------------------+-----------------------------+------------+--------------+--------+---------+\n",
      "|1832-01-01|            23.173|                        1.692|Porto Alegre|Exemplo Update|  29.74S|   51.69W|\n",
      "|1832-02-01|             22.93|                        2.661|Porto Alegre|Exemplo Update|  29.74S|   51.69W|\n",
      "|1832-03-01|            21.281|                        1.826|Porto Alegre|Exemplo Update|  29.74S|   51.69W|\n",
      "|1832-04-01|            17.697|                        2.482|Porto Alegre|Exemplo Update|  29.74S|   51.69W|\n",
      "|1832-05-01|            14.214|                        2.263|Porto Alegre|Exemplo Update|  29.74S|   51.69W|\n",
      "+----------+------------------+-----------------------------+------------+--------------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_um = spark.read.format(\"delta\").option(\"versionAsOf\", 1).load(\"s3a://warehouse/deltalake_tables\")\n",
    "df_um.filter(df_um[\"City\"] == \"Porto Alegre\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb738e6",
   "metadata": {},
   "source": [
    "Tabela após o delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3142721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+-----------------------------+----+-------+--------+---------+\n",
      "| dt|AverageTemperature|AverageTemperatureUncertainty|City|Country|Latitude|Longitude|\n",
      "+---+------------------+-----------------------------+----+-------+--------+---------+\n",
      "+---+------------------+-----------------------------+----+-------+--------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_dois = spark.read.format(\"delta\").option(\"versionAsOf\", 2).load(\"s3a://warehouse/deltalake_tables\")\n",
    "df_dois.filter(df_dois[\"City\"] == \"Porto Alegre\").show(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
